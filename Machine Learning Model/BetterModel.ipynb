{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24ae64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 338 files belonging to 25 classes.\n",
      "Found 71 files belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_dir = \"Class25_Dataset/train/\"\n",
    "test_dir = \"Class25_Dataset/test/\"\n",
    "\n",
    "\n",
    "\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                                label_mode=\"categorical\",\n",
    "                                                                                image_size=IMG_SIZE)\n",
    "                                                                                \n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6329a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 25), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de012c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"better_model_checkpoint\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                         save_weights_only=True, # save only the model weights\n",
    "                                                         monitor=\"val_accuracy\", # save the model weights which score the best validation accuracy\n",
    "                                                         save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0530ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# original_data = Sequential([\n",
    "#   preprocessing.RandomRotation(0), \n",
    "# ], name=\"original_data\")\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "  preprocessing.RandomRotation(0),\n",
    "  preprocessing.RandomFlip(\"horizontal\"),\n",
    "  preprocessing.RandomRotation(0.2), \n",
    "  preprocessing.RandomHeight(0.2),\n",
    "  preprocessing.RandomWidth(0.2),\n",
    "  preprocessing.RandomZoom(0.2),\n",
    "  preprocessing.RandomContrast(0.1)\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0e31cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x, training=False) \n",
    "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x) \n",
    "outputs = layers.Dense(len(train_data.class_names), activation=\"softmax\", name=\"output_layer\")(x) \n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a4fe52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " data_augmentation (Sequenti  (None, 224, 224, 3)      0         \n",
      " al)                                                             \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
      "                                                                 \n",
      " global_average_pooling (Glo  (None, 1280)             0         \n",
      " balAveragePooling2D)                                            \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 25)                32025     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,081,596\n",
      "Trainable params: 32,025\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "070a5171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "11/11 [==============================] - 19s 1s/step - loss: 3.2372 - accuracy: 0.0888 - val_loss: 2.9894 - val_accuracy: 0.1408\n",
      "Epoch 2/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 2.7392 - accuracy: 0.2722 - val_loss: 2.6848 - val_accuracy: 0.2113\n",
      "Epoch 3/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 2.3650 - accuracy: 0.4408 - val_loss: 2.4439 - val_accuracy: 0.3803\n",
      "Epoch 4/21\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2.0877 - accuracy: 0.5917 - val_loss: 2.2546 - val_accuracy: 0.3803\n",
      "Epoch 5/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 1.8498 - accuracy: 0.6420 - val_loss: 2.1243 - val_accuracy: 0.3944\n",
      "Epoch 6/21\n",
      "11/11 [==============================] - 12s 1s/step - loss: 1.6290 - accuracy: 0.7367 - val_loss: 2.0058 - val_accuracy: 0.4507\n",
      "Epoch 7/21\n",
      "11/11 [==============================] - 12s 1s/step - loss: 1.5059 - accuracy: 0.7574 - val_loss: 1.8942 - val_accuracy: 0.4648\n",
      "Epoch 8/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 1.3772 - accuracy: 0.7456 - val_loss: 1.8199 - val_accuracy: 0.4930\n",
      "Epoch 9/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 1.2415 - accuracy: 0.8136 - val_loss: 1.7716 - val_accuracy: 0.4789\n",
      "Epoch 10/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 1.1450 - accuracy: 0.8314 - val_loss: 1.7226 - val_accuracy: 0.5070\n",
      "Epoch 11/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 1.0781 - accuracy: 0.8728 - val_loss: 1.6616 - val_accuracy: 0.5070\n",
      "Epoch 12/21\n",
      "11/11 [==============================] - 51s 5s/step - loss: 1.0000 - accuracy: 0.8757 - val_loss: 1.6184 - val_accuracy: 0.5070\n",
      "Epoch 13/21\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.9376 - accuracy: 0.8609 - val_loss: 1.5847 - val_accuracy: 0.5070\n",
      "Epoch 14/21\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.8755 - accuracy: 0.8669 - val_loss: 1.5627 - val_accuracy: 0.5352\n",
      "Epoch 15/21\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.8216 - accuracy: 0.9201 - val_loss: 1.5439 - val_accuracy: 0.5634\n",
      "Epoch 16/21\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.7891 - accuracy: 0.9024 - val_loss: 1.5146 - val_accuracy: 0.5915\n",
      "Epoch 17/21\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.7305 - accuracy: 0.9053 - val_loss: 1.4806 - val_accuracy: 0.5775\n",
      "Epoch 18/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.6882 - accuracy: 0.9290 - val_loss: 1.4479 - val_accuracy: 0.5915\n",
      "Epoch 19/21\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.6529 - accuracy: 0.9172 - val_loss: 1.4290 - val_accuracy: 0.6197\n",
      "Epoch 20/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.6067 - accuracy: 0.9379 - val_loss: 1.4166 - val_accuracy: 0.6338\n",
      "Epoch 21/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.5624 - accuracy: 0.9290 - val_loss: 1.4080 - val_accuracy: 0.6056\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit\n",
    "history_base_model = model.fit(train_data,\n",
    "                                           epochs=21, \n",
    "                                           validation_data=test_data,\n",
    "                                           validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6ef8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Refreeze every layer except for the last 5\n",
    "for layer in base_model.layers[:-5]:\n",
    "  layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cb1a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "924bf90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4), # 10x lower learning rate than default\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a3bb344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/31\n",
      "11/11 [==============================] - 19s 1s/step - loss: 0.5247 - accuracy: 0.9379 - val_loss: 1.3619 - val_accuracy: 0.6056\n",
      "Epoch 22/31\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.4282 - accuracy: 0.9527 - val_loss: 1.3270 - val_accuracy: 0.6338\n",
      "Epoch 23/31\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3602 - accuracy: 0.9586 - val_loss: 1.2966 - val_accuracy: 0.6338\n",
      "Epoch 24/31\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.3294 - accuracy: 0.9675 - val_loss: 1.2420 - val_accuracy: 0.6338\n",
      "Epoch 25/31\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.3222 - accuracy: 0.9527 - val_loss: 1.2048 - val_accuracy: 0.6620\n",
      "Epoch 26/31\n",
      "11/11 [==============================] - 41s 4s/step - loss: 0.2330 - accuracy: 0.9822 - val_loss: 1.1914 - val_accuracy: 0.6901\n",
      "Epoch 27/31\n",
      "11/11 [==============================] - 49s 4s/step - loss: 0.2293 - accuracy: 0.9793 - val_loss: 1.1789 - val_accuracy: 0.6761\n",
      "Epoch 28/31\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.1995 - accuracy: 0.9675 - val_loss: 1.1591 - val_accuracy: 0.6761\n",
      "Epoch 29/31\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.1978 - accuracy: 0.9793 - val_loss: 1.1553 - val_accuracy: 0.6901\n",
      "Epoch 30/31\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.1879 - accuracy: 0.9763 - val_loss: 1.1916 - val_accuracy: 0.6761\n",
      "Epoch 31/31\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.1768 - accuracy: 0.9852 - val_loss: 1.1445 - val_accuracy: 0.6901\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 31\n",
    "\n",
    "history_model_fine_tune = model.fit(train_data,\n",
    "                                                     epochs=fine_tune_epochs,\n",
    "                                                     validation_data=test_data,\n",
    "                                                     validation_steps=len(test_data),\n",
    "                                                     initial_epoch=history_base_model.epoch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dcd3d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "IMAGE_SHAPE+(3,)\n",
    "test_dir = \"C:\\\\Users\\\\bhave\\\\Project-1\\\\Class25_Dataset\\\\train\\\\a\\\\2.jpeg\"\n",
    "img = cv2.imread(test_dir)\n",
    "img_resize = cv2.resize(img , IMAGE_SHAPE)\n",
    "predicted = model.predict(np.array([img_resize]))\n",
    "ind = np.argmax(predicted , axis = 1)\n",
    "index = ind[0]\n",
    "print(index)\n",
    "cv2.imshow('detected', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a095a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"better_model.json\" , \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"better_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d56ef96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "model_file = open(\"better_model.json\", \"r\")\n",
    "model_json = model_file.read()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"better_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbc034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
